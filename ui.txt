import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor
import numpy as np


st.set_page_config(page_title="Toyota Volatility Predictor", layout="wide")

st.title("ğŸ“Š GARCH + XGBoost Risk Analysis Dashboard")

uploaded_file = st.file_uploader("Upload Stock CSV", type=["csv"])

# Load default Toyota dataset
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file, parse_dates=['Date'], dayfirst=True)
else:
    df = pd.read_csv('data/toyotaData.csv', parse_dates=['Date'], dayfirst=True)

df = df.sort_values('Date').reset_index(drop=True)

# Preview
st.subheader("Data Preview")
st.dataframe(df.head())

import numpy as np
from arch import arch_model
import matplotlib.pyplot as plt

# Compute log returns
df['LogReturn'] = np.log(df['Adj Close'] / df['Adj Close'].shift(1))
df.dropna(inplace=True)

st.subheader("ğŸ“ˆ GARCH(1,1) Volatility Plot")

# Create and fit GARCH model
garch_model = arch_model(df['LogReturn'], vol='Garch', p=1, q=1)
model_fit = garch_model.fit(disp='off')
df['Volatility'] = model_fit.conditional_volatility

# Plot GARCH Volatility
fig, ax = plt.subplots(figsize=(14, 5))
ax.plot(df['Date'], df['Volatility'], color='darkorange', label='GARCH(1,1) Volatility')
ax.set_xlabel("Date")
ax.set_ylabel("Volatility")
ax.set_title("Toyota Stock â€“ GARCH(1,1) Predicted Daily Volatility")
ax.grid(True)
ax.legend()

st.pyplot(fig)

from tqdm import tqdm

st.subheader("ğŸ” Rolling GARCH Volatility Forecaster")

# Rolling window selector
window_choice = st.selectbox("Select Rolling Window Size (Days)", [7, 30, 90, 250])

if st.button("Generate Rolling Forecast"):
    st.write(f"Computing rolling GARCH volatility for a {window_choice}-day window...")

    rolling_window = window_choice
    rolling_vol = []
    rolling_dates = []

    # Use tqdm with Streamlit support (optional if tqdm causes issues)
    for i in range(rolling_window, len(df)):
        window_data = df['LogReturn'].iloc[i - rolling_window:i]
        model = arch_model(window_data, vol='Garch', p=1, q=1)
        model_fit = model.fit(disp='off')
        forecast = model_fit.forecast(horizon=1)
        predicted_vol = np.sqrt(forecast.variance.values[-1][0])
        rolling_vol.append(predicted_vol)
        rolling_dates.append(df['Date'].iloc[i])

    # Create DataFrame
    rolling_df = pd.DataFrame({
        'Date': rolling_dates,
        'RollingVolatility': rolling_vol
    })

    # Plot
    fig2, ax2 = plt.subplots(figsize=(14, 5))
    ax2.plot(rolling_df['Date'], rolling_df['RollingVolatility'], label=f'{rolling_window}-Day Rolling GARCH', color='mediumblue')
    ax2.set_title(f'Rolling GARCH Volatility Forecast ({rolling_window}-Day Window)')
    ax2.set_xlabel("Date")
    ax2.set_ylabel("Forecasted Volatility")
    ax2.legend()
    ax2.grid(True)
    st.pyplot(fig2)

st.subheader("ğŸš€ Predict Volatility using XGBoost")

if st.button("Train and Predict with XGBoost"):
    st.write("ğŸ”§ Preparing features...")

    # Feature engineering
    rolling_df['Lag1'] = rolling_df['RollingVolatility'].shift(1)
    rolling_df['Lag2'] = rolling_df['RollingVolatility'].shift(2)
    rolling_df['Lag3'] = rolling_df['RollingVolatility'].shift(3)
    rolling_df.dropna(inplace=True)

    X = rolling_df[['Lag1', 'Lag2', 'Lag3']]
    y = rolling_df['RollingVolatility']

    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)

    model = XGBRegressor(n_estimators=100, learning_rate=0.1)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    # Evaluation
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    st.success(f"âœ… MAE  : {mae:.6f}")
    st.success(f"âœ… RMSE : {rmse:.6f}")
    st.success(f"âœ… RÂ²    : {r2:.4f}")

    # Plot actual vs predicted
    fig3, ax3 = plt.subplots(figsize=(14, 5))
    ax3.plot(y_test.index, y_test, label='Actual', color='green')
    ax3.plot(y_test.index, y_pred, label='Predicted', color='red')
    ax3.set_title("ğŸ“ˆ Actual vs Predicted Volatility (XGBoost)")
    ax3.legend()
    ax3.grid(True)
    
    st.sidebar.header("ğŸ“† Date Range Selector")

# Full date range
min_date = df['Date'].min().date()
max_date = df['Date'].max().date()

# Sidebar date picker
start_date, end_date = st.sidebar.date_input(
    "Select date range:",
    [min_date, max_date],
    min_value=min_date,
    max_value=max_date
)

# Convert to pandas datetime and filter
mask = (df['Date'] >= pd.to_datetime(start_date)) & (df['Date'] <= pd.to_datetime(end_date))
filtered_df = df[mask].copy()

# Update log return from filtered data (in case of early re-use)
filtered_df['LogReturn'] = np.log(filtered_df['Adj Close'] / filtered_df['Adj Close'].shift(1))
filtered_df = filtered_df.dropna()

# Instead of
# model = arch_model(df['LogReturn'], ...)

# Use
model = arch_model(filtered_df['LogReturn'], ...)

import warnings
warnings.filterwarnings("ignore", category=UserWarning)
